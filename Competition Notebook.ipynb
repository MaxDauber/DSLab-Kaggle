{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, validation_curve, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Y     f1  f2     f3      f4  f5  f6      f7      f8  f9  ...       f14  \\\n",
      "0  1  25884   1  33.63  118596   1   0  118595  125738   1  ... -2.266430   \n",
      "1  1  34346   1  10.62  118041   1   0  117902  130913   1  ... -0.305612   \n",
      "2  1  34923   1   1.77  118327   1   0  117961  124402   1  ...  2.015561   \n",
      "3  1  80926   1  30.09  118300   1   0  117961  301218   1  ... -3.172501   \n",
      "4  1   4674   1   1.77  119921   1   0  119920  302830   1  ...  0.573767   \n",
      "\n",
      "     f15     f16     f17  f18     f19  f20  f21  f22  f23  \n",
      "0   1945  118450  119184    1  121372    1    1    1    2  \n",
      "1  15385  117945  292795    1  259173    1    1    1    1  \n",
      "2   7547  118933  290919    1  118784    1    1    1    1  \n",
      "3   4933  118458  118331    1  307024    1    1    1    2  \n",
      "4  13836  142145    4673    1  128230    1    1    1  620  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "       f1  f2     f3      f4  f5  f6      f7      f8  f9  f10  ...       f14  \\\n",
      "0   37733   1   1.77  118603   1   0  118602  118097   1    0  ...  2.453740   \n",
      "1  312129   1   3.54  118052   1   0  117961  290919   1    4  ... -0.012317   \n",
      "2   24884   1  23.01  118300   1   0  117961  302830   1    0  ...  1.000000   \n",
      "3    4674   1   1.77  119091   1   0  119062  118036   1    9  ...  1.000000   \n",
      "4   68725   1   3.54  118300   1   0  117961  171056   1    0  ... -0.503250   \n",
      "\n",
      "     f15     f16     f17  f18     f19  f20  f21  f22  f23  \n",
      "0  13881  117941  117887    1  117885    1    1    1    1  \n",
      "1  14638  118992  290919    1  118321    1    1    1    7  \n",
      "2    770  119181    4673    1  128230    1    1    1   14  \n",
      "3  16752  143531  290919    1  117905    1    1    1   81  \n",
      "4   4945  118360  118638    1  118636    1    1    1    1  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(16383, 24)\n",
      "(16385, 23)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data-science-comp-f2020/train_final.csv').iloc[:,1:-1]\n",
    "test = pd.read_csv('data-science-comp-f2020/test_final.csv').iloc[:,1:-1]\n",
    "y = train.Y\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "print(np.shape(train))\n",
    "print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Samples from both train and test\n",
    "all_data = pd.concat((train.iloc[:,1:-1],\n",
    "                      test.iloc[:,1:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some useful functions for below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_test(preds, name):\n",
    "    ids = pd.read_csv('data-science-comp-f2020/test_final.csv').iloc[:,0]\n",
    "    np.shape(ids)\n",
    "    temp = pd.concat([ids, preds], axis=1)\n",
    "    temp.to_csv(f'results/{name}.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brief Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train.Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "likely_categorical = {}\n",
    "for var in train.columns:\n",
    "    likely_categorical[var] = 1.*train[var].nunique()/train[var].count() < 0.05 #or some other threshold\n",
    "del likely_categorical['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train\n",
    "if \"Y\" in data.columns:\n",
    "    del data[\"Y\"]\n",
    "dtrain = xgb.DMatrix(data=data, label=y)\n",
    "dtest = xgb.DMatrix(data=test)\n",
    "params = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 20,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 2, \n",
    "    'verbosity':1} \n",
    "\n",
    "steps = 20\n",
    "num_round = 10\n",
    "xgb_model_counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtrain, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08859605 0.911404  ]\n",
      " [0.2567079  0.7432921 ]\n",
      " [0.06564732 0.9343527 ]\n",
      " ...\n",
      " [0.06564732 0.9343527 ]\n",
      " [0.09559052 0.9044095 ]\n",
      " [0.18103012 0.8189699 ]]\n"
     ]
    }
   ],
   "source": [
    "soft_preds = model.predict(dtest)\n",
    "print(soft_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Y\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "...   ..\n",
      "16380  1\n",
      "16381  1\n",
      "16382  1\n",
      "16383  1\n",
      "16384  1\n",
      "\n",
      "[16385 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "hard_preds = pd.DataFrame([np.argmax(line) for line in soft_preds])\n",
    "hard_preds.columns = [\"Y\"]\n",
    "np.shape(hard_preds)\n",
    "print(hard_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_counter += 1\n",
    "model_name = datetime.today().strftime('%Y_%m_%d') + \"xgboost_\" + str(xgb_model_counter)\n",
    "model.save_model(f'models/{model_name}.model')\n",
    "model_params = f\"models/{model_name}_params.json\"\n",
    "with open(model_params, 'w') as fp:\n",
    "    json.dump(params, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "export_test(hard_preds, model_name)\n",
    "print(xgb_model_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pt 2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info on what cross validation is. RMSE is just the RMS error in the model: https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Ridge Regression###\n",
    "model_ridge = Ridge()\n",
    "\n",
    "#Run the cross validation using different alpha parameters, test cross-validation on each one\n",
    "alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\n",
    "cv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n",
    "            for alpha in alphas]\n",
    "###Plotting Ridge Regression###\n",
    "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
    "cv_ridge.plot()\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_alphas = [1, 0.1, 0.001, 0.0005]\n",
    "model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model_lasso.coef_, index = train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "                     coef.sort_values().tail(10)])\n",
    "\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = 11\n",
    "accuracies = []\n",
    "non_zero = []\n",
    "Cs = np.logspace(-5, 5, num=n_values)\n",
    "cv = StratifiedShuffleSplit(n_splits=n_values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(cv.split(train,y)):\n",
    "    print(\"running training for C =\", Cs[i])\n",
    "    X_train, X_test = train[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    logreg_l1 = LogisticRegression(C=Cs[i], penalty='l1',solver='saga', multi_class='multinomial', tol=0.1)\n",
    "    logreg_l1.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = logreg_l1.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
